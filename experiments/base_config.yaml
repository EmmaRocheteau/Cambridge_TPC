data:
  data_dir: "data/"
  train_file: "train.csv"
  val_file: "val.csv"
  test_file: "test.csv"

hardware:
  accelerator: "auto"  # Options: "cpu", "gpu", "auto"
  devices: "auto"      # Number of devices to use or "auto"
  strategy: "auto"     # Options: "ddp", "dp", null, "auto"
  precision: 32        # Options: 16, 32

model:
  type: "TPC"  # Model type to instantiate
  features: 128  # Number of features (F) for encoding
  no_flat_features: 9  # Number of static features
  num_layers: 6
  dropout: 0.05
  temp_dropout_rate: 0.02
  kernel_size: 3
  temp_kernels: [6, 6, 6, 6, 6, 6]
  point_sizes: [14, 14, 14, 14, 14, 14]
  momentum: 0.1
  last_linear_size: 16  # Output dimension

tasks:
  los_prediction:
    type: "regression"
    loss_weight: 1.0
    metrics: ["msle", "mse", "mae", "mape", "r2"]
    regression_bins: [1, 2, 3, 4, 5, 6, 7, 8, 14]  # For binned accuracy

  mortality:
    type: "binary"
    loss_weight: 1.0
    metrics: ["auroc", "auprc", "accuracy", "balanced_accuracy"]

  next_destination:
    type: "multiclass"
    num_classes: 5
    loss_weight: 1.0
    metrics: ["accuracy", "balanced_accuracy", "f1"]

training:
  seed: 42
  epochs: 100
  batch_size: 128  # Increased batch size
  learning_rate: 0.0045  # Optimal learning rate
  weight_decay: 0.00053  # L2 regularization
  early_stopping:
    monitor: "val_total_loss"
    patience: 10
    mode: "min"
  grad_clip: 1.0
  optimizer:
    type: "adam"
    weight_decay: 0.01
  scheduler:
    type: "reduce_lr_on_plateau"
    patience: 5
    factor: 0.5
    monitor: "val_total_loss"

experiment:
  name: null  # Will be set at runtime
  results_dir: "experiments/results"
  save_best: true
  save_last: true
